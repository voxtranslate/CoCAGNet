# COLLABORATIVE CROSS-ATTENTION GUIDED NETWORK (CoCAGNet) FOR SUPER RESOLUTION
# Abstract
Digital imaging is a rapidly evolving field which has made single-image super-resolution (SISR) techniques such as conventional convolutional neural networks (CNN) and attention-based techniques, popular vital tools for image quality improvement. However, limited convolutional receptive fields are often exhibited by CNN-based algorithms, leading to a struggle in establishing global contextual information; thus, limiting generalization capabilities. In parallel, to save computational cost, self-attention computation is typically restricted to non-overlapping windows; thus, limiting the spatial range of information exploited by attention-based networks. To address these issues, an optimized Collaborative Cross-Attentive Guided (CoCAG) network, is proposed in this study. CoCAG is constructed by stacking Collaborative Cross-Attention Blocks (CoCABlock) and Upscale Attentive blocks (UPA-B). On the one side, CoCABlock combines the criss-cross attention with a convolutional-based bottle neck attention module which includes a self-attention and channel attention. This synergy promotes nonlocal feature fusion and enhance complex scenes reconstruction accuracy. Conversely, the triple attention-based UPA-B models across long-range dependencies in images, by increasing the features spatial resolution, and refining upscale features. Furthermore, we explicitly preserve low-level details, ensure pixel-wise accuracy, while reducing artifacts and maintaining color fidelity through a balanced optimization of multiple objectives, leveraging the strengths of our newly introduced Wasserstein Pixel-Regularized (WPR) loss. As per the extensive experiments, we argue that our proposed CoCAG method yields commendable results, outperforming the state-of-the-art methods on the benchmark dataset, in terms of image details and structure recovery, while its generalization can enable handle an arbitrary super-resolution image reconstruction.
